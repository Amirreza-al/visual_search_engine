{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-25T07:19:46.496075Z",
     "iopub.status.busy": "2025-06-25T07:19:46.495823Z",
     "iopub.status.idle": "2025-06-25T07:19:58.220753Z",
     "shell.execute_reply": "2025-06-25T07:19:58.220059Z",
     "shell.execute_reply.started": "2025-06-25T07:19:46.496051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# ! pip install faiss-cpu gradio transformers torchvision torch --quiet\n",
    "! pip install faiss-cpu gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:20:11.681814Z",
     "iopub.status.busy": "2025-06-25T07:20:11.681319Z",
     "iopub.status.idle": "2025-06-25T07:20:45.155572Z",
     "shell.execute_reply": "2025-06-25T07:20:45.154995Z",
     "shell.execute_reply.started": "2025-06-25T07:20:11.681782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 07:20:31.504073: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750836031.737648      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750836031.804919      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:20:59.173136Z",
     "iopub.status.busy": "2025-06-25T07:20:59.172172Z",
     "iopub.status.idle": "2025-06-25T07:21:04.711927Z",
     "shell.execute_reply": "2025-06-25T07:21:04.711130Z",
     "shell.execute_reply.started": "2025-06-25T07:20:59.173109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21872c5f1ab413e85e70eca310fb785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8416a7b7684feaa59426e04b21933f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1afaaed38484f7ca1761c40af5d03a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79d717f1b6e437d8cf155e02b6153e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbfc4d504184f31b6654f79a924549f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b115dbf1e92743419bc073d016dd55cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b52cb4e3eb493bafbfe494202d4350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5b728712e24551818fdfef59ed40a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb77bd30ec0b45ac94d8912a8a003ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------- 1. Global Configuration ---------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMAGE_FOLDER = \"Dataset\"  # Folder containing images to index\n",
    "INDEX_FILE = \"output/faiss_index.bin\"\n",
    "FEATURES_FILE = \"outputfeatures.npy\"\n",
    "FILENAMES_FILE = \"output/filenames.npy\"\n",
    "TOP_K = 5  # Number of results to return\n",
    "\n",
    "\n",
    "# --------- 2. CLIP Model Initialization ---------\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:21:31.428785Z",
     "iopub.status.busy": "2025-06-25T07:21:31.428507Z",
     "iopub.status.idle": "2025-06-25T07:21:31.433836Z",
     "shell.execute_reply": "2025-06-25T07:21:31.433242Z",
     "shell.execute_reply.started": "2025-06-25T07:21:31.428765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_clip_features function was defined successfully\n"
     ]
    }
   ],
   "source": [
    "# --------- 3. Feature Extraction Function ---------\n",
    "def extract_clip_features(image: Image.Image):\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "        image_features /= image_features.norm(p=2, dim=-1, keepdim=True)  # L2 normalize\n",
    "    return image_features.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "print('extract_clip_features function was defined successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:21:33.638340Z",
     "iopub.status.busy": "2025-06-25T07:21:33.637745Z",
     "iopub.status.idle": "2025-06-25T07:21:33.846357Z",
     "shell.execute_reply": "2025-06-25T07:21:33.845674Z",
     "shell.execute_reply.started": "2025-06-25T07:21:33.638315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_index function was defined successfully\n"
     ]
    }
   ],
   "source": [
    "# --------- 4. Build Index from Dataset ---------\n",
    "def build_index(image_folder: str):\n",
    "    features = []\n",
    "    filenames = []\n",
    "    counter = 0\n",
    "    \n",
    "    print(\"Extracting features from dataset...\")\n",
    "    for filename in tqdm(os.listdir(image_folder)):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "            path = os.path.join(image_folder, filename)\n",
    "            try:\n",
    "                image = Image.open(path).convert(\"RGB\")\n",
    "                feature = extract_clip_features(image)\n",
    "                features.append(feature)\n",
    "                filenames.append(path)\n",
    "            except Exception as e:\n",
    "                counter += 1\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    index = faiss.IndexFlatL2(features.shape[1])\n",
    "    index.add(features)\n",
    "\n",
    "    # Save index and metadata\n",
    "    faiss.write_index(index, INDEX_FILE)\n",
    "    np.save(FEATURES_FILE, features)\n",
    "    np.save(FILENAMES_FILE, np.array(filenames))\n",
    "\n",
    "    print(f\"Indexing complete. {counter} files were passed\")\n",
    "    return index, filenames\n",
    "\n",
    "print('build_index function was defined successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:21:36.206458Z",
     "iopub.status.busy": "2025-06-25T07:21:36.205747Z",
     "iopub.status.idle": "2025-06-25T07:21:36.211327Z",
     "shell.execute_reply": "2025-06-25T07:21:36.210662Z",
     "shell.execute_reply.started": "2025-06-25T07:21:36.206431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_or_build_index function was defined successfully\n"
     ]
    }
   ],
   "source": [
    "# --------- 5. Load or Build FAISS Index ---------\n",
    "def load_or_build_index():\n",
    "    if os.path.exists(INDEX_FILE) and os.path.exists(FILENAMES_FILE):\n",
    "        print(\"Loading saved index...\")\n",
    "        index = faiss.read_index(INDEX_FILE)\n",
    "        filenames = np.load(FILENAMES_FILE, allow_pickle=True)\n",
    "        print(\"Loading saved index completed\")\n",
    "    else:\n",
    "        print(\"No saved index found. Building new index...\")\n",
    "        index, filenames = build_index(IMAGE_FOLDER)\n",
    "    return index, filenames\n",
    "\n",
    "print('load_or_build_index function was defined successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:21:38.718731Z",
     "iopub.status.busy": "2025-06-25T07:21:38.718157Z",
     "iopub.status.idle": "2025-06-25T07:21:38.723417Z",
     "shell.execute_reply": "2025-06-25T07:21:38.722757Z",
     "shell.execute_reply.started": "2025-06-25T07:21:38.718703Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_similar_images function was defined successfully\n"
     ]
    }
   ],
   "source": [
    "# --------- 6. Search Function ---------\n",
    "def search_similar_images(query_image: Image.Image):\n",
    "    query_vector = extract_clip_features(query_image)\n",
    "    distances, indices = index.search(query_vector, TOP_K)\n",
    "    results = [filenames[i] for i in indices[0]]\n",
    "    return results\n",
    "\n",
    "print('search_similar_images function was defined successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:21:41.461460Z",
     "iopub.status.busy": "2025-06-25T07:21:41.460788Z",
     "iopub.status.idle": "2025-06-25T07:28:30.114664Z",
     "shell.execute_reply": "2025-06-25T07:28:30.113986Z",
     "shell.execute_reply.started": "2025-06-25T07:21:41.461437Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved index found. Building new index...\n",
      "Extracting features from dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24999/24999 [06:47<00:00, 61.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete.\n"
     ]
    }
   ],
   "source": [
    "# --------- 7. Gradio Interface ---------\n",
    "def gradio_search_interface(input_image):\n",
    "    results = search_similar_images(input_image)\n",
    "    return [Image.open(img_path) for img_path in results]\n",
    "\n",
    "index, filenames = load_or_build_index()\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_search_interface,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload a Query Image\"),\n",
    "    outputs=[gr.Image(label=f\"Result {i+1}\") for i in range(TOP_K)],\n",
    "    title=\"CLIP-Based Image Search Engine\",\n",
    "    description=\"Upload an image to find visually and semantically similar images using CLIP and FAISS.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T07:28:38.205765Z",
     "iopub.status.busy": "2025-06-25T07:28:38.205075Z",
     "iopub.status.idle": "2025-06-25T07:28:39.652157Z",
     "shell.execute_reply": "2025-06-25T07:28:39.651586Z",
     "shell.execute_reply.started": "2025-06-25T07:28:38.205739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://defc1dc1670fea1fba.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://defc1dc1670fea1fba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1899756,
     "sourceId": 3112810,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
